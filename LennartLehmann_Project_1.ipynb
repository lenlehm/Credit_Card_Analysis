{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FYS-STK4155 Assignment #1 - Credit Card Fault Detection\n",
    "\n",
    "Evaluation of Project number: 1 <br />\n",
    "Name: Lennart Lehmann (ERASMUS Student)\n",
    "\n",
    "## Abstract \n",
    "\n",
    "In this project we show that there are several credit card misuses based on the given dataset. \n",
    "By analysing the dataset with tools like Lasso Regression and some Classification techniques from the awesome SciKit-Learn toolbox we can see that there have been x transaction misuses over the entire recording time. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this work is to search for Credit Card payments in time. The question we wanted to answer is how possible is a person based on the given dataset to not pay back his debt in time.\n",
    "We were given a dataset which has 25 variables (which I will call features from now on) such as ID, Sex, Age, PAY_0 until PAY_6 (to show the Repayment status in specific months) and so on and so forth.\n",
    "This dataset included 102.234 transactions for each single feature. So we have an overall Matrix **X** of the shape $ X \\in {\\rm I\\!R^{102234\\times25}}$\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "      \\begin{bmatrix} x_{1,1} & x_{1,2} & ... & x_{1,25} \\\\\n",
    "                                 x_{2,1} & x_{2,2} & ... & x_{2,25} \\\\\n",
    "                                   \\vdots & \\ddots & \\ddots & \\vdots \\\\\n",
    "                                  x_{102234,1} & x_{102234,2} & ... & x_{102234,25}\n",
    "             \\end{bmatrix}\\qquad\n",
    "$$\n",
    "\n",
    "Here we deal with several unnecessary features that we can neglect for further analysis. ID for example would potentially just bias our estimator and we want to have an unbiased classificator that can deal with the data independent of one's name, since it could turn out to discriminate against specific names.\n",
    "\n",
    "\n",
    "## Formalism\n",
    "\n",
    "During our project we used several techniques to accomplish our goal.\n",
    "Foremost we have to mention that the dataset consists of Data along with its targets or output values. \n",
    "Hence, we will use a **supervised learning technique** since we have the corresponding outputs for each single transaction recorded. With this knowledge we already restrict our methods by supervised learning techniques and we can look for some algorithms that can handle numerical data for classification tasks.\n",
    "First of all we needed to properly clean the data, i.e. getting rid of all NaN values in our matrix as well as deleting some irrelevant features (such as ID).\n",
    "For Classification purposes we used a **Supported Vector Machine (SVM)** which creates a hyperplane among the classes with a maximum margin between the datapoints. This technique is used very often to deal with classification problems.\n",
    "For Benchmarking purposes (and due to the fact that I am a big fan of Random forests) I will also use this method to benchmark the results of the SVM against the Random forests. \n",
    "\n",
    "SVM solve following Cost problem:\n",
    "\n",
    "$$\n",
    "\\sigma_{xy} =\\frac{1}{n} \\sum_{i=0}^{n-1}(x_i- \\overline{x})(y_i- \\overline{y}).\n",
    "$$\n",
    "\n",
    "*Dive into other stuff I did and explain it ehaustively*\n",
    "\n",
    "\n",
    "\n",
    "## Code and Implementation\n",
    "*Readability of Code, Implementation and testing and discussion of Benchmarks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import visual libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# import the SKLearn palette\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and check the first entries\n",
    "pathToHappiness = os.getcwd() + '\\\\assignment1_data.csv'\n",
    "happinessDataFrame = pd.read_csv(pathToHappiness)\n",
    "happinessDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenny\\\\Documents\\\\Studium_Robotics (M.Sc.)\\\\Semester 3 - Oslo ERASMUS\\\\01_Applied Data Analysis and Machine Learning\\\\Project 1\\\\assignment1_data.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape of the dataframe and check whether we have null values in our Happyness Df\n",
    "print(happinessDataFrame.shape)\n",
    "print(happinessDataFrame.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "In order to get a first glimpse of the data, I usually take a look at the distribution of the labels (True vs. False). <br />\n",
    "Here we can already see, whether we deal with an **imbalanced dataset**, which would lead to a really bad classification at the end, or whether we have approximately the same numbers for True and False labels which would be a balanced dataset. <br />\n",
    "Furthermore, we also have to check for any *NaN* values, which would also distort our classifier. <br /> \n",
    "\n",
    "Personally, I like making correlation plots to see how the features depend on one another which helps in the later steps to drop specific features in order to reduce the computation complexity. <br />\n",
    "\n",
    "Another important step is to convert any categorical value to numerical values, since the classifiers can't handle non-numeric data. This can be done by one-hot encoding or similiar techniques. <br /> \n",
    "\n",
    "Lastly, normalizing the data helps to deal with outliers better, since they will not weight that much anymore and in general we will have a conform input for each single feature into our classifier. <br />\n",
    "<br /> \n",
    "\n",
    "So, let's get our hands dirty and massage the data the way it loves it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's make a deep dive into our data and first check the labels to see with which kind of data we have to deal this time\n",
    "entireTransactions = happinessDataFrame.shape[0]\n",
    "disgustingFraudsters = happinessDataFrame[happinessDataFrame['Class'] == 1]\n",
    "sweetNonFraudsters = happinessDataFrame[happinessDataFrame['Class'] == 0]\n",
    "\n",
    "relativeFraudsters = len(disgustingFraudsters)/entireTransactions\n",
    "relativeNonFraudsters = len(sweetNonFraudsters)/entireTransactions\n",
    "\n",
    "# print the % value of Fraudsters vs. non Fraudsters to get a better feeling of our data at hand\n",
    "print('FRAUDSTERS: {}% vs. NON FRAUDSTERS: {}%'.format(relativeFraudsters*100, relativeNonFraudsters*100))\n",
    "\n",
    "# let's visualize our balance of fraudster vs non fraudsters\n",
    "labels = ['non-fraud','fraud']\n",
    "classes = pd.value_counts(happinessDataFrame['Class'], sort = True)\n",
    "classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since we also have categorical data we have to convert it to numerical data\n",
    "# for this purpose I just use standard conversion techniques like one-hot encoding for the gender, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's check how the features correlate with one another\n",
    "correlation_matrix = happinessDataFrame.corr()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "sns.heatmap(correlation_matrix,vmax=0.8,square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plot\n",
    "\n",
    "based on our feature correlation plot we can see that not so many features correlaate with each other. Thus, dropping one feature would not affect any other one.\n",
    "Here, since the ID might lead to some unwanted bias and it does not correlate with any other feature I will drop this column to reduce the complexity of the data and have an unbiased, non discriminating predictor at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, since the dataset is highly unbiased we have to balance it by using the same amount of fraudsters vs. non-fraudsters\n",
    "# Let's shuffle the data before creating the subsamples\n",
    "df = happinessDataFrame.sample(frac=1)\n",
    "\n",
    "frauds = happinessDataFrame[happinessDataFrame['Class'] == 1]\n",
    "non_frauds = happinessDataFrame[happinessDataFrame['Class'] == 0][:len(frauds)]\n",
    "\n",
    "new_dataFrame = pd.concat([non_frauds, frauds])\n",
    "# Shuffle dataframe rows\n",
    "new_dataFrame = new_df.sample(frac=1, random_state=38)\n",
    "# Let's plot the Transaction class against the Frequency\n",
    "labels = ['non frauds','fraud']\n",
    "classes = pd.value_counts(new_dataFrame['Class'], sort = True)\n",
    "classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's drop the unnecessary features we don't want our classifier to utilize for its predictions\n",
    "features = new_dataFrame.drop(['Class'], axis = 1)\n",
    "features = features.drop(['ID'], axis = 1)\n",
    "labels = pd.DataFrame(new_dataFrame['Class'])\n",
    "\n",
    "feature_array = features.values\n",
    "label_array = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally split our data into train (80%) and test (20%) datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_array,label_array,test_size=0.20)\n",
    "\n",
    "# Normalize our data to handle outliers in a better way and have conform inputs over all features\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor (k-NN) as first approach\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) is going to the SK Learn kNN function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k nearest neighbor approach to ckeck the baseline <-- we want to beat this accuracy\n",
    "neighbours = np.arange(1,30) # evaluate up to 30 neighbors\n",
    "train_accuracy = np.empty(len(neighbours))\n",
    "test_accuracy = np.empty(len(neighbours))\n",
    "\n",
    "# evaluate the optimal number of k for our dataset\n",
    "for i,k in enumerate(neighbours):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\", n_jobs=-1)\n",
    "    \n",
    "    #Fit the model (.ravel() - function is flattening the array)\n",
    "    knn.fit(X_train,y_train.ravel())\n",
    "    \n",
    "    #Compute accuracy on the training and test set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train.ravel())\n",
    "    test_accuracy[i] = knn.score(X_test, y_test.ravel())\n",
    "    \n",
    "# plot the different accuracies w.r.t. the amount of k-neighbors\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbours, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbours, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# select the maximum accuracy (of test dataset)\n",
    "idx = np.where(test_accuracy == max(test_accuracy))\n",
    "optimal_k = neighbours[idx]\n",
    "\n",
    "# fit the final k-NN classifier to our dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k, algorithm=\"kd_tree\", n_jobs=-1)\n",
    "knn.fit(X_train,y_train.ravel())\n",
    "\n",
    "# # save the model \n",
    "# filename = os.getcwd() + 'finalized_kNN_model.sav'\n",
    "# joblib.dump(knn, filename)\n",
    "\n",
    "# # load model again and predict\n",
    "# knn = joblib.load(filename)\n",
    "# knn_predicted_test_labels = knn.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "knn_accuracy_score  = accuracy_score(y_test, knn_predicted_test_labels)\n",
    "knn_MSE             = mean_squared_error(y_test, knn_predicted_test_labels)\n",
    "knn_r2              = r2_score(y_test, knn_predicted_test_labels)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(knn_accuracy_score, knn_MSE, knn_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, knn_predicted_test_labels)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) is going to the SK Learn SVM function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the best soft margin model with different parameter settings\n",
    "param_grid = { \n",
    "    'C': np.logspace(-3, 2, 6),\n",
    "    'gamma': np.logspace(-3, 2, 6),\n",
    "    'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "}\n",
    "# set up our SVM classifier\n",
    "svm_model = SVC(gamma='scale', c=c_range)\n",
    "\n",
    "# check for the optimal paramters using GridSearch\n",
    "parameterSearch_SVM = GridSearchCV(estimator=svm_model, param_grid=param_grid, refit=True)\n",
    "parameterSearch_SVM.fit(X_train, y_train) \n",
    "print(parameterSearch_SVM.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# Since the GridSearchCV already stores the best parameters, we can straight predict with that model\n",
    "svm_predicted = parameterSearch_SVM.predict(X_test)\n",
    "\n",
    "# # save the model \n",
    "# filename = os.getcwd() + 'finalized_SVM_model.sav'\n",
    "# joblib.dump(parameterSearch_SVM, filename)\n",
    "\n",
    "# # load model again and predict\n",
    "# svm_model = joblib.load(filename)\n",
    "# svm_predicted = svm_model.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "svm_accuracy_score  = accuracy_score(y_test, svm_predicted)\n",
    "svm_MSE             = mean_squared_error(y_test, svm_predicted)\n",
    "svm_r2              = r2_score(y_test, svm_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(svm_accuracy_score, svm_MSE, svm_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, svm_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) is going to the SK Learn Random Forest function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up our Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier(n_jobs=-1, max_features='sqrt', n_estimators=50, oob_score=True)\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 30, 50, 100, 200, 400, 600, 800, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [3, 6, 10, 13, 15, 17, None],\n",
    "}\n",
    "# evaluate the best paramters for Random Forest\n",
    "parameterSearch_RFC = GridSearchCV(estimator=rfc_model, param_grid=param_grid, refit=True)\n",
    "parameterSearch_RFC.fit(X_train, y_train) \n",
    "print(parameterSearch_SVM.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# predict the outputs for our test dataset\n",
    "randomForest_predicted = parameterSearch_RFC.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "rfc_accuracy_score  = accuracy_score(y_test, randomForest_predicted)\n",
    "rfc_MSE             = mean_squared_error(y_test, randomForest_predicted)\n",
    "rfc_r2              = r2_score(y_test, randomForest_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(rfc_accuracy_score, rfc_MSE, rfc_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, randomForest_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layered Perceptron (Neural Network)\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) describes all the MLP Paramters in the SK Learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the parameters we want to test as well as the classifier itself\n",
    "parameters={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(128, 256, 256, 64), (111, 168, 66), (122, 122), , (256, 512, 364, 168, 44), (123, 127, 55), (22, 33, 44, 22)],\n",
    "'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"]\n",
    "}\n",
    "mlp_classifier = MLPClassifier(n_jobs=-1, max_features='sqrt', n_estimators=50, oob_score=True)\n",
    "\n",
    "# create the grid Search\n",
    "mlp = GridSearchCV(estimator=mlp_classifier, param_grid=parameters, n_jobs=-1, refit=True)\n",
    "mlp.fit(X_train, y_train) \n",
    "print(mlp.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# predict the values of our test dataset\n",
    "mlp_predicted = mlp.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "mlp_accuracy_score  = accuracy_score(y_test, mlp_predicted)\n",
    "mlp_MSE             = mean_squared_error(y_test, mlp_predicted)\n",
    "mlp_r2              = r2_score(y_test, mlp_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(mlp_accuracy_score, mlp_MSE, mlp_r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, mlp_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of all tested Algorithms\n",
    "\n",
    "Now we have seen that each algorithm performs differently on the underlying dataset. \n",
    "In order to have it also more visually appealing, in the following chart we can see an overlay of each algorithm with its best tested Paramters on the Test set by using the Accuracy Score of each single algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objects = ('Random Forest', 'SVM', 'k-NN', 'MLP')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [rfc_accuracy_score, svm_accuracy_score, knn_accuracy_score, mlp_accuracy_score]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy across the ' + str(len(objects)) + ' used algorithms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "As shown in the previous section (**Code and Implementation**) we see that there have been some people who are at risk to not pay their debt in time. Thus, you can already send these people some help and offer some other duties they have to follow, etc. Here we only took a look at the data we have at hand (25 features) and neglect all the other (key) factors that could help us getting more insights about the persons' circumstances. <br />\n",
    "However, we compared three different kind of Machine Learning algorithms with each other and benchmarked each single one of them. <br />\n",
    "The overall plot tells us that Random Forests achieved better results than kNN or SVM, respectively. \n",
    "Since I have only limited computing power as well as time, I just used random variables for the Hyperparamter Search for all three Algorithms. <br />\n",
    "Keep in mind that it might be possible that SVM outperforms Random Forest with a different kind of Parameter Setting, but for our case we can definitely say that the Random Forest had the best accuracy with the testes Paramters. <br />\n",
    "On big problem with the dataset was is that it is unbalanced and we need to have balanced classes for each of the classification outputs otherwise our predictor will be biased (for further read on the impact on unbalanced datasets please check out [this thread](https://www.researchgate.net/post/Effect_of_imbalanced_data_on_machine_learning)) <br />\n",
    "For better Accuracy of the Credit Card dataset one could scrape the web to see where they made the transactions and derive valuable insights based on that. Basically adding more data and more features to our training and test set to have a better expressiveness of our algorithm and our predictions. \n",
    "\n",
    "*Dive into the Analysis and plots from the previous section --> Correlation of single features with each other...* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We see that this dataset gives us already some really interesting facts and we can derive some nice predictions based on that. \n",
    "Now that we predicted some potential 'threats' in our customer base we can just directly approach these guys and try to help them out with offering them certain duties or suggesting different options for the credit card. \n",
    "Other ways to improve the accuracy of our system would be to either \n",
    "    1.) generate more data with more features\n",
    "    2.) apply state of the art artificial neural networks (deep learning) algorithms such as DenseNet, etc.\n",
    "If we go with 1.) we would need more time since every payment will be recorded and we would get more data based upon time. Another way to artifically generate more data would be by intelligently use other methods to renrich the feature space of our data. So instead of having 25 features we could augment it to 30 with additional features such as *usual shopping district*, *usual time of payments*, etc. \n",
    "\n",
    "The 2.) method suggests a modern approach of classification by modelling as good as possible to our training set and have predictions which usually outperform SVMs or Linear Regression methods for more complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Rajaratne, M. (2018). *Data Pre-Processing Techniques you should know*, retrieved from https://towardsdatascience.com/data-pre-processing-techniques-you-should-know-8954662716d6, lastly accessed on 20th September 2019. <br />\n",
    "[2] Bishop, C.M. (2011). *Pattern Recognition and Machine Learning*. Cambridge: Springer. <br />\n",
    "[3] Duda, R. O. (2007). *Pattern Classification*. San Jose: Wiley. <br />\n",
    "[4] Murphy, K. P. (2007). *Machine Learning: A probabilistic Perspective*. Camebridge: MIT Press. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
