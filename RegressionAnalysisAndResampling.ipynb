{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FYS-STK4155 Project #1 - Regression Analysis\n",
    "\n",
    "Evaluation of Project number: 1 <br />\n",
    "Name: Lennart Lehmann (ERASMUS Student)\n",
    "\n",
    "## Abstract \n",
    "\n",
    "In this project we parameterize digital terrain data by using three different regression algorithms: <br /> \n",
    "**1.) Linear Regression / Ordinary Least Squares (OLS)** <br />\n",
    "**2.) Ridge Regression** <br />\n",
    "**3.) Lasso Regression** <br />\n",
    "Utilizing Cross-Validation as resampling technique to judge the bias and variance of the different models. <br /> \n",
    "We find that the OLS method scores the best for our underlying data, followed by the Lasso Regression and ending up last with the Ridge Regression.\n",
    "Displaying the bias-variance tradeoff reveals that we our model is mostly dominated in the bias area and the variance basically no effect on the mean error.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Linear regression methods are fundamental in the field of statistical modelling. In the simplest\n",
    "variant of regression analysis modelling a response dependent on some predictor variables\n",
    "a linear ansatz is assumed for the relasionship between response and predictors. The\n",
    "ansatz is linear in the sense of a linear combination of (possibly non-linear) functions of a single\n",
    "predictor. This linearity allows the matrix-vector equations resulting from minimizing the\n",
    "error between the observed data (targets) and the predicted model data to be solved, which\n",
    "is the main advantage of the method (and the main reason why linear regression is extensively\n",
    "used today). In the modern society, data is ubiquitous and abundant. However, with an ever increasing volume\n",
    "of data availability, drawing sensible conclusions about the relasionships between variables\n",
    "is non-trivial. Suppose you were given a complete set of statistics about every school\n",
    "district in Norway: The grade point average (and indeed individual grades) of every single\n",
    "student, the size and composition (in terms of nationalities, gender, height, weight, etc.) of every\n",
    "class, a full description of the teaching load of every teacher, as well as their personal data,\n",
    "educational history, and work history. Such a data set might be readily available, but drawing\n",
    "conclusions from it is not easy. Say e.g. that you wanted to know if increasing the number of\n",
    "teachers per pupil would result in overall better grades. Or a more complex question what\n",
    "is the most efficient way to increase the overall grades of students?\n",
    "Such questions pertaining to relationships between data of varying types are possible to answer\n",
    "using regression analysis, and bound on the statistical significance of the answers are possible\n",
    "to find. In the following, we will consider a much simpler toy problem as a simple introduction\n",
    "to the topic: Fitting a real valued function of two real variables. We will start out by considering\n",
    "the theory behind linear regression.\n",
    "\n",
    "This dataset included 102.234 transactions for each single feature. So we have an overall Matrix $\\boldsymbol{X}$ of the shape $ X \\in {\\rm I\\!R^{n\\times p}}$ <br /> \n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "      \\begin{bmatrix} x_{1,1} & x_{1,2} & ... & x_{1,p} \\\\\n",
    "                                 x_{2,1} & x_{2,2} & ... & x_{2,p} \\\\\n",
    "                                   \\vdots & \\ddots & \\ddots & \\vdots \\\\\n",
    "                                  x_{n,1} & x_{n,2} & ... & x_{n,p}\n",
    "             \\end{bmatrix}\\qquad \n",
    "$$\n",
    "\n",
    "\n",
    "## Formalism\n",
    "\n",
    "Within the scope of this project we used the three aforementioned techniques to accomplish our goal.\n",
    "We will dive into the theory behind those algorithms and implement them afterwards accordingly.\n",
    "<br /> \n",
    "\n",
    "### Ordinary Least Squares (OLS)\n",
    "\n",
    "Considering a case with $p$ predictors and of $n$ measured samples. Along we have the target $y$, a vector of size *n*: $\\boldsymbol{y} =[y_1, y_2,\\dots, y_{n}]^T$. The predictors are organized in a matrix $\\boldsymbol{X}$, called *design matrix*, with the shape $\\boldsymbol{X}\\in {\\mathbb{R}}^{n\\times p}$\n",
    "In regression we want to construct a function <br /> \n",
    "\n",
    "$$\n",
    "\\boldsymbol{y} = \\boldsymbol{X}\\beta + \\epsilon \\tag{1}\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ denotes a zero mean normal distributed noise of our linear model. \n",
    "$\\beta$ is an unknown vector that counts to estimate in the regression problem. <br /> \n",
    "\n",
    "The objective function (also known as Cost function) of linear regression is thus the best possible linear fit  <br />\n",
    "\n",
    "$$\n",
    " C(\\boldsymbol{X}, \\boldsymbol{\\beta})= \\frac{1}{n}\\left\\{(\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y})^T(\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y})\\right\\}. \\tag{2}\n",
    "$$\n",
    "\n",
    "By minimizing the Mean of Squared Errors (MSE): <br />\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)\\right\\}. \\tag{3}\n",
    "$$\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Considering the Objective function from Linear Regression, which is the Mean Squarred Error (MSE), we could also express it as follows: <br />\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\sum_{i=0}^{n-1}\\left(y_i-\\tilde{y}_i\\right)^2=\\frac{1}{n}\\vert\\vert \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\vert\\vert_2^2, \\tag{4}\n",
    "$$\n",
    "\n",
    "We can further simplify it with the expression of the norm-2 vector (a.k.a $L^2$ regularization): <br />\n",
    "\n",
    "$$\n",
    "\\vert\\vert \\boldsymbol{x}\\vert\\vert_2 = \\sqrt{\\sum_i x_i^2}. \\tag{5}\n",
    "$$\n",
    "\n",
    "By adding a regularization parameter $\\lambda$, that keeps the weights from taking abnormous values and help to fight against overfitting, we obtain <br />\n",
    "In ridge regression we include a **regularizer**. This involves a new cost function which leads to a new estimate for the weights $\\boldsymbol{\\beta}$. This results in a penalized regression problem. The cost function is given by: <br />\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\vert\\vert \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\vert\\vert_2^2+\\lambda\\vert\\vert \\boldsymbol{\\beta}\\vert\\vert_2^2 \\tag{6}\n",
    "$$\n",
    "\n",
    "This leads to our new optimization equation: <br />\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\vert\\vert \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\vert\\vert_2^2+\\lambda\\vert\\vert \\boldsymbol{\\beta}\\vert\\vert_1 \\tag{7}\n",
    "$$\n",
    "\n",
    "\n",
    "### Lasso Regression\n",
    "\n",
    "Lasso Regression is very similiar to Ridge Regression, **but** instead of taking the $L^2$ regularization, Lasso utilizes the $L^1$ regularization, which is defined as follows: <br />\n",
    "\n",
    "$$\n",
    "\\vert\\vert \\boldsymbol{x}\\vert\\vert_1 = \\sum_i \\vert x_i\\vert. \\tag{8}\n",
    "$$\n",
    "\n",
    "Hence, our optimization equation is just a slight twist to our known Ridge Regression to eventually obtain the following Lasso Regression: <br />\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\vert\\vert \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\vert\\vert_2^2+\\lambda\\vert\\vert \\boldsymbol{\\beta}\\vert\\vert_1 \\tag{9}\n",
    "$$\n",
    "\n",
    "In the **Least Absolute Shrinkage and Selection Operator** (LASSO)-method we obtain a third cost function. <br />\n",
    "$$\n",
    "\\begin{equation}\n",
    "    C(\\boldsymbol{X}, \\boldsymbol{\\beta}; \\lambda) = (\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y})^T(\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y}) + \\lambda \\sqrt{\\boldsymbol{\\beta}^T\\boldsymbol{\\beta}}.\n",
    "\\label{_auto22} \\tag{10}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### Resampling methods\n",
    "\n",
    "Resampling methods are crucial in Machine learning, especially when dealing with limited amount of data. <br />\n",
    "The main idea behind resampling is to repeatedly draw (different) samples from the dataset and split those accrodingly into test - and training data. Every single run a model gets fitted on the training data set and eventually evaluated with its test dataset. The final output will then be the average of the testing accuracy of all performed runs. <br />\n",
    "However, this nice feature comes to the cost of computation. Since models have to be fitted every single time and evaluated on different subsets of the data, resampling methods such as *k-fold Cross Validation* or *Bootstrapping* are computationally\n",
    "expensive. <br />\n",
    "*Bootstrapping* is a statistical technique for estimating quantities about a population by taking averages over estimates from several smaller data samples. <br />\n",
    "Those samples are constructed by drawing random observations from a large data sample (usually the training set in Machine Learning) with replacement. <br />\n",
    "By taking repeatedly small samples of a population, the bootstrap resampling method calculates the statistics (Mean Squarred Error (MSE), bias, variance) of those samples. This will result in an indication of the appropriate order of model complexity. <br />\n",
    "\n",
    "#### Cross- Validation\n",
    "\n",
    "Cross-Validation is used to split the entire data into 2 groups, calles *training* and *test data*. A model's performance is always evaluated on the *test data* by calculating the accuracy metrics on this data set with the given targets and model's predictions. <br />\n",
    "By splitting the entire data into *k-even subsets* (where $k \\in [1, 2, ..., n]$), we obtain a training dataset of size *k-1* subsets and one subset of test data. This technique is calles *k-fold Cross Validation*. <br /> \n",
    "Afterwards each single subset will be once used as test data which will in turn lead to *k* runs of the exact same model (same hyperparameters) but different training and test data for each run. Hence, each run returns a test error on its underlying test data. By averaging the test errors by the *k* number of runs, we obtain the final model accuracy.<br /> \n",
    "Thus, *Cross-Validation* is used to asses the performance of a given model. <br />\n",
    "\n",
    "### Terrain Data\n",
    "\n",
    "We were given a dataset containing an area of Tinn, Norway with its land surface topology and a resolution of roughly 30m (1 arc-second).  <br> \n",
    "The data was retrieved from U.S. Department of the Interior U.S. Geological Survey's (USGS) EarthExplorer [1] website. <br />\n",
    "USGS stores data from the Shuttle Radar Topography Mission (SRTM), which maps the earth's land surface topology with the aforementioned resolution. <br />\n",
    "This project will use SRTM data taken from the EarthExplorer website as the foundation of the terrain parametrization. The specific terrain data we will use in the present project is taken from the Mosvatn Austfjell area in the municipality of Tinn in Telemark county, Norway. A visual representation of the data is shown in Fig. 1. <br />\n",
    "\n",
    "\n",
    "#### Franke's Function\n",
    "\n",
    "The [Franke function](http://www.dtic.mil/dtic/tr/fulltext/u2/a081688.pdf) was originally developed to test and rate different surface interpolation techniques.\n",
    "\n",
    "The Franke function, which is a weighted sum of four exponentials reads as follows: <br />\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x,y) &= \\frac{3}{4}\\exp{\\left(-\\frac{(9x-2)^2}{4} - \\frac{(9y-2)^2}{4}\\right)}+\\frac{3}{4}\\exp{\\left(-\\frac{(9x+1)^2}{49}- \\frac{(9y+1)}{10}\\right)} \\\\\n",
    "&+\\frac{1}{2}\\exp{\\left(-\\frac{(9x-7)^2}{4} - \\frac{(9y-3)^2}{4}\\right)} -\\frac{1}{5}\\exp{\\left(-(9x-4)^2 - (9y-7)^2\\right) }.\n",
    "\\end{align*} \\tag{11}\n",
    "$$\n",
    "\n",
    "The function will be defined for $x,y\\in [0,1]$.\n",
    "\n",
    "\n",
    "\n",
    "## Code and Implementation\n",
    "*Readability of Code, Implementation and testing and discussion of Benchmarks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8bc87cf28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Franke Function\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "\n",
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4\n",
    "\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-0.10, 1.20)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least Squares \n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "\n",
    "def OLSFit(X, y):\n",
    "'''\n",
    "        Performs the ordinary linear regression fit using the *from scratch* \n",
    "        implementation. The matrix calculation performed corresponds to \n",
    "                   T   -1  T\n",
    "             =  X   X    X  y,\n",
    "                         \n",
    "        where b is the vector of beta values, Xt denotes the tranpose of X and \n",
    "        inv(A) is the inverse of the matrix A.\n",
    "        If the matrix Xt X is found to be too singular to numerically invert, \n",
    "        a SVD is used to perform the fit, as \n",
    "                      -1  T\n",
    "             =  V      U  y\n",
    "                         \n",
    "'''\n",
    "\n",
    "    U,S,Vt = np.linalg.svd(X, full_matrices=True)\n",
    "    S_inverse = np.zeros(shape=X.shape)\n",
    "    S_inverse[:S.shape[0], :S.shape[0]] = np.diag(1.0 / S)\n",
    "    beta = np.dot(Vt.T, np.dot(S_inverse.T, np.dot(U.T, y)))\n",
    "    return np.dot(X, beta) # prediction\n",
    "    \n",
    "def ridge(X, y):\n",
    "    beta = np.dot(np.linalg.inv(np.dot(np.transpose(X),X) + self.lambda_ * np.eye(X.shape[1])), np.dot(np.transpose(X),y))\n",
    "    return np.dot(X, beta) # prediction\n",
    "\n",
    "def scipyRidge(lamda, X, y) :\n",
    "    if lamda == None :\n",
    "        raise ValueError(\"No lambda value set for Ridge regression.\")\n",
    "    regression = linear_model.Ridge(fit_intercept=True, alpha=self.lambda_)\n",
    "    regression.fit(X,y)\n",
    "    beta = regression.coef_\n",
    "    beta[0] = regression.intercept_\n",
    "    return regression.predict(X)\n",
    "\n",
    "def scipyLasso(lamda, X, y) :\n",
    "    if lamda == None:\n",
    "        raise ValueError(\"No lambda value set for Lasso regression.\")\n",
    "    regression = linear_model.Lasso(fit_intercept=True, max_iter=100000, alpha=self.lambda_)\n",
    "    regression.fit(X,y)\n",
    "    beta = regression.coef_\n",
    "    beta[0] = regression.intercept_\n",
    "    return regression.predict(X)\n",
    "    \n",
    "def predict(X, beta):\n",
    "    return np.dot(X, beta)\n",
    "\n",
    "def getMSE(targets, predictions):\n",
    "     return metrics.mean_squared_error(targets, predictions)\n",
    "    \n",
    "def getR2(targets, predictions):\n",
    "     return metrics.r2_score(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Design Matrix\n",
    "def CreateDesignMatrix_X(x, y, n = 5):\n",
    "    \"\"\"\n",
    "    Function for creating a design X-matrix with rows [1, x, y, x^2, xy, xy^2 , etc.]\n",
    "    Input is x and y mesh or raveled mesh, keyword agruments n is the degree of the polynomial you want to fit.\n",
    "    \"\"\"\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n+1)*(n+2)/2)\n",
    "    X = np.ones((N,l))\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = x**(i-k) * y**k\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def computeMatrix(matrix, x, degree):\n",
    "    ind = 1\n",
    "    for i in range(1, degree+1):\n",
    "        for j in range(i+1):\n",
    "            matrix[:, ind] = x[:,0]**(i-j) * x[:,1]**j\n",
    "            ind += 1\n",
    "\n",
    "def getMatrixPolynom(self, x):\n",
    "    \"\"\"Computes the design matrix for a polynomial of a given combined degree\n",
    "    Computes the design matrix of 2D polynomial type with degree specified \n",
    "    in the input to the constructor. The first column contains unity, \n",
    "    the subsequent columns are evaluated as \n",
    "                            \n",
    "          X   =  p  x , y   \n",
    "           ij     j  i   i  \n",
    "\n",
    "    with X being the design matrix and (x, y) being the 2D input data set. \n",
    "    The polynomial p is the j-th polynomial in the set of linearly \n",
    "    independent combined polynomials \n",
    "                   2    2         3    3    2        2    4    4\n",
    "        x ,  y ,  x ,  y , xy ,  x ,  y ,  x y ,  x y ,  x ,  y , ...\n",
    "    of combined total degree self.degree. There are n(n+3)/2 such \n",
    "    different monomials/polynomials in a set of degree n.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    x : numpy.array\n",
    "        The data set, a 2D numpy array, used for the construction of\n",
    "        the design matrix\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Degree 1\n",
    "    0:  lambda x,y : x,\n",
    "    1:  lambda x,y : y,\n",
    "    # Degree 2\n",
    "    2:  lambda x,y : x**2        ,\n",
    "    3:  lambda x,y : x    * y    ,\n",
    "    4:  lambda x,y :        y**2 ,\n",
    "    # Degree 3\n",
    "    5:  lambda x,y : x**3        ,\n",
    "    6:  lambda x,y : x**2 * y    ,   \n",
    "    7:  lambda x,y : x    * y**2 ,\n",
    "    8:  lambda x,y :        y**3 ,\n",
    "    \"\"\"\n",
    "    N = x.shape\n",
    "    N = N[0]\n",
    "\n",
    "    # The total number of polynomials up to and including combined \n",
    "    # total degree self.degree, i.e. 2, 5, 9, 14, 20, 27... . This\n",
    "    # is just the sum of the integers, \n",
    "    #\n",
    "    #     n+1         n (n + 3)\n",
    "    #         k   =    =  P\n",
    "    #     k=2             2          n\n",
    "    #\n",
    "\n",
    "    P = int(degree*(degree+3)/2)\n",
    "\n",
    "    matrix = np.zeros(shape=(N, P+1))\n",
    "    matrix[:,0] = 1.0\n",
    "    computeMatrix(matrix, x, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit Linear Regression with x,y up to 5th order to it\n",
    "for degree in [2, 3, 4, 5]:\n",
    "    designMatrix = DesignMatrix('polynomial2D', degree)\n",
    "    leastSquares = LeastSquares(backend='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Let's start with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8a72cc550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# A seed just to ensure that the random numbers are the same for every run.\n",
    "# Useful for eventual debugging.\n",
    "np.random.seed(3155)\n",
    "\n",
    "# Generate the data.\n",
    "nsamples = 100\n",
    "x = np.random.randn(nsamples)\n",
    "y = 3*x**2 + np.random.randn(nsamples)\n",
    "\n",
    "## Cross-validation on Ridge regression using KFold only\n",
    "\n",
    "# Decide degree on polynomial to fit\n",
    "poly = PolynomialFeatures(degree = 6)\n",
    "# Decide which values of lambda to use\n",
    "nlambdas = 500\n",
    "lambdas = np.logspace(-3, 5, nlambdas)\n",
    "\n",
    "# Initialize a KFold instance\n",
    "k = 5\n",
    "kfold = KFold(n_splits = k)\n",
    "\n",
    "# Perform the cross-validation to estimate MSE\n",
    "scores_KFold = np.zeros((nlambdas, k))\n",
    "\n",
    "i = 0\n",
    "for lmb in lambdas:\n",
    "    ridge = Ridge(alpha = lmb)\n",
    "    j = 0\n",
    "    for train_inds, test_inds in kfold.split(x):\n",
    "        xtrain = x[train_inds]\n",
    "        ytrain = y[train_inds]\n",
    "\n",
    "        xtest = x[test_inds]\n",
    "        ytest = y[test_inds]\n",
    "\n",
    "        Xtrain = poly.fit_transform(xtrain[:, np.newaxis])\n",
    "        ridge.fit(Xtrain, ytrain[:, np.newaxis])\n",
    "\n",
    "        Xtest = poly.fit_transform(xtest[:, np.newaxis])\n",
    "        ypred = ridge.predict(Xtest)\n",
    "\n",
    "        scores_KFold[i,j] = np.sum((ypred - ytest[:, np.newaxis])**2)/np.size(ypred)\n",
    "\n",
    "        j += 1\n",
    "    i += 1\n",
    "\n",
    "\n",
    "estimated_mse_KFold = np.mean(scores_KFold, axis = 1)\n",
    "estimated_mse_sklearn = np.zeros(nlambdas)\n",
    "i = 0\n",
    "for lmb in lambdas:\n",
    "    ridge = Ridge(alpha = lmb)\n",
    "\n",
    "    X = poly.fit_transform(x[:, np.newaxis])\n",
    "    estimated_mse_folds = cross_val_score(ridge, X, y[:, np.newaxis], scoring='neg_mean_squared_error', cv=kfold)\n",
    "\n",
    "    # cross_val_score return an array containing the estimated negative mse for every fold.\n",
    "    # we have to the the mean of every array in order to get an estimate of the mse of the model\n",
    "    estimated_mse_sklearn[i] = np.mean(-estimated_mse_folds)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "## Plot and compare the slightly different ways to perform cross-validation\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(np.log10(lambdas), estimated_mse_sklearn, label = 'cross_val_score')\n",
    "plt.plot(np.log10(lambdas), estimated_mse_KFold, 'r--', label = 'KFold')\n",
    "\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('mse')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import visual libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# import the SKLearn palette\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining some variables that all algorihtms share\n",
    "cross_val = 10 # let's do a 10-fold cross validation for our hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the data and check the first entries\n",
    "pathToHappiness = os.getcwd() + '\\\\assignment1_data.csv'\n",
    "happinessDataFrame = pd.read_csv(pathToHappiness)\n",
    "happinessDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenny\\\\Documents\\\\Studium_Robotics (M.Sc.)\\\\Semester 3 - Oslo ERASMUS\\\\01_Applied Data Analysis and Machine Learning\\\\Project 1\\\\assignment1_data.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape of the dataframe and check whether we have null values in our Happyness Df\n",
    "print(happinessDataFrame.shape)\n",
    "print(happinessDataFrame.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "In order to get a first glimpse of the data, I usually take a look at the distribution of the labels (True vs. False). <br />\n",
    "Here we can already see, whether we deal with an **imbalanced dataset**, which would lead to a really bad classification at the end, or whether we have approximately the same numbers for True and False labels which would be a balanced dataset. <br />\n",
    "Furthermore, we also have to check for any *NaN* values, which would also distort our classifier. <br /> \n",
    "\n",
    "Personally, I like making correlation plots to see how the features depend on one another which helps in the later steps to drop specific features in order to reduce the computation complexity. <br />\n",
    "\n",
    "Another important step is to convert any categorical value to numerical values, since the classifiers can't handle non-numeric data. This can be done by one-hot encoding or similiar techniques. <br /> \n",
    "\n",
    "Lastly, normalizing the data helps to deal with outliers better, since they will not weight that much anymore and in general we will have a conform input for each single feature into our classifier. <br />\n",
    "<br /> \n",
    "\n",
    "So, let's get our hands dirty and massage the data the way it loves it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's make a deep dive into our data and first check the labels to see with which kind of data we have to deal this time\n",
    "entireTransactions = happinessDataFrame.shape[0]\n",
    "disgustingFraudsters = happinessDataFrame[happinessDataFrame['Class'] == 1]\n",
    "sweetNonFraudsters = happinessDataFrame[happinessDataFrame['Class'] == 0]\n",
    "\n",
    "relativeFraudsters = len(disgustingFraudsters)/entireTransactions\n",
    "relativeNonFraudsters = len(sweetNonFraudsters)/entireTransactions\n",
    "\n",
    "# print the % value of Fraudsters vs. non Fraudsters to get a better feeling of our data at hand\n",
    "print('FRAUDSTERS: {}% vs. NON FRAUDSTERS: {}%'.format(relativeFraudsters*100, relativeNonFraudsters*100))\n",
    "\n",
    "# let's visualize our balance of fraudster vs non fraudsters\n",
    "labels = ['non-fraud','fraud']\n",
    "classes = pd.value_counts(happinessDataFrame['Class'], sort = True)\n",
    "classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since we also have categorical data we have to convert it to numerical data\n",
    "# for this purpose I just use standard conversion techniques like one-hot encoding for the gender, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's check how the features correlate with one another\n",
    "correlation_matrix = happinessDataFrame.corr()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "sns.heatmap(correlation_matrix,vmax=0.8,square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plot\n",
    "\n",
    "based on our feature correlation plot we can see that not so many features correlaate with each other. Thus, dropping one feature would not affect any other one.\n",
    "Here, since the ID might lead to some unwanted bias and it does not correlate with any other feature I will drop this column to reduce the complexity of the data and have an unbiased, non discriminating predictor at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, since the dataset is highly unbiased we have to balance it by using the same amount of fraudsters vs. non-fraudsters\n",
    "# Let's shuffle the data before creating the subsamples\n",
    "df = happinessDataFrame.sample(frac=1)\n",
    "\n",
    "frauds = happinessDataFrame[happinessDataFrame['Class'] == 1]\n",
    "non_frauds = happinessDataFrame[happinessDataFrame['Class'] == 0][:len(frauds)]\n",
    "\n",
    "new_dataFrame = pd.concat([non_frauds, frauds])\n",
    "# Shuffle dataframe rows\n",
    "new_dataFrame = new_df.sample(frac=1, random_state=38)\n",
    "# Let's plot the Transaction class against the Frequency\n",
    "labels = ['non frauds','fraud']\n",
    "classes = pd.value_counts(new_dataFrame['Class'], sort = True)\n",
    "classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's drop the unnecessary features we don't want our classifier to utilize for its predictions\n",
    "features = new_dataFrame.drop(['Class'], axis = 1)\n",
    "features = features.drop(['ID'], axis = 1)\n",
    "labels = pd.DataFrame(new_dataFrame['Class'])\n",
    "\n",
    "feature_array = features.values\n",
    "label_array = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally split our data into train (80%) and test (20%) datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_array,label_array,test_size=0.20)\n",
    "\n",
    "# Normalize our data to handle outliers in a better way and have conform inputs over all features\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor (k-NN) as first approach\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) is going to the SK Learn kNN function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k nearest neighbor approach to ckeck the baseline <-- we want to beat this accuracy\n",
    "neighbours = np.arange(1,30) # evaluate up to 30 neighbors\n",
    "train_accuracy = np.empty(len(neighbours))\n",
    "test_accuracy = np.empty(len(neighbours))\n",
    "\n",
    "# evaluate the optimal number of k for our dataset\n",
    "for i,k in enumerate(neighbours):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\", n_jobs=-1)\n",
    "    \n",
    "    #Fit the model (.ravel() - function is flattening the array)\n",
    "    knn.fit(X_train,y_train.ravel())\n",
    "    \n",
    "    #Compute accuracy on the training and test set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train.ravel())\n",
    "    test_accuracy[i] = knn.score(X_test, y_test.ravel())\n",
    "    \n",
    "# plot the different accuracies w.r.t. the amount of k-neighbors\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbours, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbours, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# select the maximum accuracy (of test dataset)\n",
    "idx = np.where(test_accuracy == max(test_accuracy))\n",
    "optimal_k = neighbours[idx]\n",
    "\n",
    "# fit the final k-NN classifier to our dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k, algorithm=\"kd_tree\", n_jobs=-1)\n",
    "knn.fit(X_train,y_train.ravel())\n",
    "\n",
    "# # save the model \n",
    "# filename = os.getcwd() + 'finalized_kNN_model.sav'\n",
    "# joblib.dump(knn, filename)\n",
    "\n",
    "# # load model again and predict\n",
    "# knn = joblib.load(filename)\n",
    "# knn_predicted_test_labels = knn.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "knn_accuracy_score  = accuracy_score(y_test, knn_predicted_test_labels)\n",
    "knn_MSE             = mean_squared_error(y_test, knn_predicted_test_labels)\n",
    "knn_r2              = r2_score(y_test, knn_predicted_test_labels)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(knn_accuracy_score, knn_MSE, knn_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, knn_predicted_test_labels)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) is going to the SK Learn SVM function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the best soft margin model with different parameter settings\n",
    "param_grid = { \n",
    "    'C': np.logspace(-3, 2, 6),\n",
    "    'gamma': np.logspace(-3, 2, 6),\n",
    "    'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "}\n",
    "# set up our SVM classifier\n",
    "svm_model = SVC(gamma='scale', c=c_range)\n",
    "\n",
    "# check for the optimal paramters using GridSearch\n",
    "parameterSearch_SVM = GridSearchCV(estimator=svm_model, param_grid=param_grid, refit=True, cv=cross_val)\n",
    "parameterSearch_SVM.fit(X_train, y_train) \n",
    "print(parameterSearch_SVM.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# Since the GridSearchCV already stores the best parameters, we can straight predict with that model\n",
    "svm_predicted = parameterSearch_SVM.predict(X_test)\n",
    "\n",
    "# # save the model \n",
    "# filename = os.getcwd() + 'finalized_SVM_model.sav'\n",
    "# joblib.dump(parameterSearch_SVM, filename)\n",
    "\n",
    "# # load model again and predict\n",
    "# svm_model = joblib.load(filename)\n",
    "# svm_predicted = svm_model.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "svm_accuracy_score  = accuracy_score(y_test, svm_predicted)\n",
    "svm_MSE             = mean_squared_error(y_test, svm_predicted)\n",
    "svm_r2              = r2_score(y_test, svm_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(svm_accuracy_score, svm_MSE, svm_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, svm_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) is going to the SK Learn Random Forest function with all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up our Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier(n_jobs=-1, max_features='sqrt', n_estimators=50, oob_score=True)\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 30, 50, 100, 200, 400, 600, 800, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [3, 6, 10, 13, 15, 17, None],\n",
    "}\n",
    "# evaluate the best paramters for Random Forest\n",
    "parameterSearch_RFC = GridSearchCV(estimator=rfc_model, param_grid=param_grid, refit=True, cv=cross_val)\n",
    "parameterSearch_RFC.fit(X_train, y_train) \n",
    "print(parameterSearch_SVM.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# predict the outputs for our test dataset\n",
    "randomForest_predicted = parameterSearch_RFC.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "rfc_accuracy_score  = accuracy_score(y_test, randomForest_predicted)\n",
    "rfc_MSE             = mean_squared_error(y_test, randomForest_predicted)\n",
    "rfc_r2              = r2_score(y_test, randomForest_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(rfc_accuracy_score, rfc_MSE, rfc_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, randomForest_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layered Perceptron (Neural Network)\n",
    "\n",
    "[this link](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) describes all the MLP Paramters in the SK Learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the parameters we want to test as well as the classifier itself\n",
    "parameters={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(128, 256, 256, 64), (111, 168, 66), (122, 122), , (256, 512, 364, 168, 44), (123, 127, 55), (22, 33, 44, 22)],\n",
    "'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"]\n",
    "}\n",
    "mlp_classifier = MLPClassifier(n_jobs=-1, max_features='sqrt', n_estimators=50, oob_score=True)\n",
    "\n",
    "# create the grid Search\n",
    "mlp = GridSearchCV(estimator=mlp_classifier, param_grid=parameters, n_jobs=-1, refit=True, cv=cross_val)\n",
    "mlp.fit(X_train, y_train) \n",
    "print(mlp.best_params_)\n",
    "print('\\n')\n",
    "print(' ------------------------------------------------------------------------------------- ')\n",
    "\n",
    "# predict the values of our test dataset\n",
    "mlp_predicted = mlp.predict(X_test)\n",
    "\n",
    "# get the score\n",
    "mlp_accuracy_score  = accuracy_score(y_test, mlp_predicted)\n",
    "mlp_MSE             = mean_squared_error(y_test, mlp_predicted)\n",
    "mlp_r2              = r2_score(y_test, mlp_predicted)\n",
    "\n",
    "print(\"Accuracy Score: {} \\nMean Squared Error: {} \\nR2 Score: {}\".format(mlp_accuracy_score, mlp_MSE, mlp_r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion Matrix for visualizing the classification task\n",
    "LABELS = ['Non-Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test, mlp_predicted)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of all tested Algorithms\n",
    "\n",
    "Now we have seen that each algorithm performs differently on the underlying dataset. \n",
    "In order to have it also more visually appealing, in the following chart we can see an overlay of each algorithm with its best tested Paramters on the Test set by using the Accuracy Score of each single algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objects = ('Random Forest', 'SVM', 'k-NN', 'MLP')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [rfc_accuracy_score, svm_accuracy_score, knn_accuracy_score, mlp_accuracy_score]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy across the ' + str(len(objects)) + ' used algorithms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "As shown in the previous section (**Code and Implementation**) we see that there have been some people who are at risk to not pay their debt in time. Thus, you can already send these people some help and offer some other duties they have to follow, etc. Here we only took a look at the data we have at hand (25 features) and neglect all the other (key) factors that could help us getting more insights about the persons' circumstances. <br />\n",
    "However, we compared three different kind of Machine Learning algorithms with each other and benchmarked each single one of them. <br />\n",
    "The overall plot tells us that Random Forests achieved better results than kNN or SVM, respectively. \n",
    "Since I have only limited computing power as well as time, I just used random variables for the Hyperparamter Search for all three Algorithms. <br />\n",
    "Keep in mind that it might be possible that SVM outperforms Random Forest with a different kind of Parameter Setting, but for our case we can definitely say that the Random Forest had the best accuracy with the testes Paramters. <br />\n",
    "On big problem with the dataset was is that it is unbalanced and we need to have balanced classes for each of the classification outputs otherwise our predictor will be biased (for further read on the impact on unbalanced datasets please check out [this thread](https://www.researchgate.net/post/Effect_of_imbalanced_data_on_machine_learning)) <br />\n",
    "For better Accuracy of the Credit Card dataset one could scrape the web to see where they made the transactions and derive valuable insights based on that. Basically adding more data and more features to our training and test set to have a better expressiveness of our algorithm and our predictions. \n",
    "\n",
    "*Dive into the Analysis and plots from the previous section --> Correlation of single features with each other...* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We see that this dataset gives us already some really interesting facts and we can derive some nice predictions based on that. \n",
    "Now that we predicted some potential 'threats' in our customer base we can just directly approach these guys and try to help them out with offering them certain duties or suggesting different options for the credit card. \n",
    "Other ways to improve the accuracy of our system would be to either \n",
    "    1.) generate more data with more features\n",
    "    2.) apply state of the art artificial neural networks (deep learning) algorithms such as DenseNet, etc.\n",
    "If we go with 1.) we would need more time since every payment will be recorded and we would get more data based upon time. Another way to artifically generate more data would be by intelligently use other methods to renrich the feature space of our data. So instead of having 25 features we could augment it to 30 with additional features such as *usual shopping district*, *usual time of payments*, etc. \n",
    "\n",
    "The 2.) method suggests a modern approach of classification by modelling as good as possible to our training set and have predictions which usually outperform SVMs or Linear Regression methods for more complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] EarthExplorer website: https://earthexplorer.usgs.gov/, Used Dataset: Norway, last visited 05.09.2019 <br />\n",
    "[2] Bishop, C.M. (2011). *Pattern Recognition and Machine Learning*. Cambridge: Springer. <br />\n",
    "[3] Duda, R. O. (2007). *Pattern Classification*. San Jose: Wiley. <br />\n",
    "[4] Murphy, K. P. (2007). *Machine Learning: A probabilistic Perspective*. Camebridge: MIT Press. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
